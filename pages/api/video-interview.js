import fs from "fs";
import multer from "multer";
import Groq from "groq-sdk";
import ffmpeg from "fluent-ffmpeg";
import ffmpegPath from "ffmpeg-static";

ffmpeg.setFfmpegPath(ffmpegPath);

export const config = {
  api: { bodyParser: false },
};

const upload = multer({ dest: "uploads/" });

function runMiddleware(req, res, fn) {
  return new Promise((resolve, reject) => {
    fn(req, res, (result) => {
      if (result instanceof Error) reject(result);
      resolve(result);
    });
  });
}

const groq = new Groq({ apiKey: process.env.GROQ_API_KEY });

// -----------------------------
// Convert WebM → WAV
// -----------------------------
function extractAudio(inputPath) {
  return new Promise((resolve, reject) => {
    const outputPath = inputPath + ".wav";

    ffmpeg(inputPath)
      .noVideo()
      .audioCodec("pcm_s16le")
      .format("wav")
      .save(outputPath)
      .on("end", () => resolve(outputPath))
      .on("error", (err) => reject(err));
  });
}

// -----------------------------
// Transcribe WAV audio
// -----------------------------
async function transcribeAudio(filePath) {
  try {
    const resp = await groq.audio.transcriptions.create({
      file: fs.createReadStream(filePath),
      model: "whisper-large-v3",
    });

    return resp.text;
  } catch (err) {
    console.error("Groq Transcription Error:", err);
    throw new Error("Failed to transcribe audio");
  }
}

// -----------------------------
// Generate follow-up AI response
// -----------------------------
async function generateAIResponse(userText) {
  const resp = await groq.chat.completions.create({
    model: "llama-3.1-8b-instant",
    messages: [
      {
        role: "system",
        content:
          "You are a professional AI interviewer. Reply concisely and naturally. Do not ask multiple questions at once."
      },
      { role: "user", content: userText },
    ],
  });

  return resp.choices[0].message.content;
}

// -----------------------------
// Evaluate user's answer for human vs AI
// -----------------------------
async function evaluateAnswer(userText) {
  try {
    const prompt = `You are an assistant that evaluates whether the following answer appears written/spoken by a human or generated by an AI model.
Return only JSON with fields: humanPercent (0-100 integer), aiPercent (0-100 integer), briefReason (one-line).
Answer: """${userText}"""`;

    const resp = await groq.chat.completions.create({
      model: "llama-3.1-8b-instant",
      messages: [{ role: "user", content: prompt }],
      max_tokens: 200,
      temperature: 0,
    });

    const reply = resp.choices?.[0]?.message?.content?.trim() || "";

    // Parse JSON from Groq's reply
    let humanPercent = 50;
    let aiPercent = 50;
    try {
      const maybeJson = reply.match(/\{[\s\S]*\}/);
      if (maybeJson) {
        const parsed = JSON.parse(maybeJson[0]);
        humanPercent = parsed.humanPercent ?? humanPercent;
        aiPercent = parsed.aiPercent ?? aiPercent;
      }
    } catch (e) {
      console.warn("Evaluation parse error:", e);
    }

    return { humanPercent, aiPercent };
  } catch (err) {
    console.error("Evaluate Answer Error:", err);
    return { humanPercent: 50, aiPercent: 50 };
  }
}

// -----------------------------
// MAIN API HANDLER
// -----------------------------
export default async function handler(req, res) {
  try {
    await runMiddleware(req, res, upload.single("video"));

    const videoFile = req.file;
    if (!videoFile) {
      return res.status(400).json({ error: "No video file uploaded" });
    }

    console.log("Uploaded:", videoFile);

    // Convert video → WAV audio
    const audioPath = await extractAudio(videoFile.path);
    console.log("Converted to audio:", audioPath);

    // Transcribe user answer
    const transcription = await transcribeAudio(audioPath);
    console.log("Transcription:", transcription);

    // -------------------------
    // Evaluate user's answer
    // -------------------------
    const { humanPercent, aiPercent } = await evaluateAnswer(transcription);

    // Generate AI response
    const aiResponse = await generateAIResponse(transcription);

    return res.status(200).json({
      transcription,
      aiResponse,
      humanPercent,
      aiPercent,
    });
  } catch (err) {
    console.error("Video Interview Error:", err);
    return res.status(500).json({ error: err.message });
  }
}
